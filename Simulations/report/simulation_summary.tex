\documentclass[12pt]{article}
\usepackage{amsmath,amsfonts}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{float}

\renewcommand{\baselinestretch}{1}
\topmargin 0in \headheight 0.0in \textheight 9in \textwidth 6.5in
\oddsidemargin 0.1in \evensidemargin 0.1in

\begin{document}

\section*{Methods}

In this study, we conducted two simulations to evaluate the performace of LASSO
models in identifying important features in high-dimensional data. The first
simulation assumes sparsity of the features in the pixel space, while the
second simulation assumes sparsity in the frequency space.

The pixel space refers to the original high-dimensional space where each
dimension represents a pixel in an image. In this space, features are directly
observed and may have inherent correlations. Conversely, the frequency space is
a transformed version of the pixel space, obtained through techniques like
eigen decomposition.

Suppose \( X \) is a column vector representing 256 pixels. Its covariance
matrix, \( \Sigma \), is defined to have an exponential correlation structure,
where \( \Sigma_{i j}=-\exp (\operatorname{dist}(i, j)) \). Here, \(
\operatorname{dist}(i, j) \) is the distance between the pixels \( i \) and \(
j \) in a \( 16 \times 16 \) matrix.

Let \( V \) be the matrix of eigenvectors of \( \Sigma \), with each column
representing an eigenvector. We can transform the random vector \( X \) into
the frequency space by \( X_{\text {freq }}=V^T X \). The covariance matrix of
\( X_{\text {freq }} \) is given by \(
\operatorname{cov}\left(X_{\mathrm{freq}}\right)=V^T \Sigma V \), which is a
diagonal matrix.

For the simulations, in each iteration, we randomly generate \( X_{\text {freq
}} \) from a multivariate normal distribution with the covariance matrix \(\
operatorname{cov}\left(X_{\text {freq }}\right) \). We repeat this process 1000
times. Then, we calculate \( X \) as \( X=V X_{\text {freq }} \).

In the first simulation, we assume sparsity in the coefficient vectors in the
pixel space. The coefficient vector \( \beta \) was specified to have non-zero
values exclusively within a central \( 8 \times 8 \) region. The response
variable \( y \) was drawn from a binomial distribution with success
probabilities determined by \( \eta = X \beta \). The non-zero coefficients in
\( \beta \) were chosen such that the probability \( p = \frac{1}{1 +
\exp(-\eta)} \) was uniformly distributed across interval \( [0, 1] \).

In the second simulation, we assume sparsity in the coefficient vectors in the
frequency space. We defined a sparse coefficient vector \( b \) in the
frequency space, where most of the 256 entries were zero and a randomly 10\%
were non-zero. The response variable \( y \) was generated similarly to the
first simulation, ensuring \( p = \frac{1}{1 + \exp(-\eta)} \) was evenly
distributed.

For both simulations, we fit two models: one using the covariates in the pixel
space and another using the covariates in the frequency space. Each dataset,
generated in size \( 1000 \times 256 \) and representing images of \( 16 \times
16 \) pixels, was split into training (80\%) and test (20\%) sets. The
regularization parameter \( \lambda \) was tuned using cross-validation with
the default binomial deviance metric. The dataset was divided into 10 folds,
with the model trained and validated iteratively across these folds, varying \(
\lambda \). The optimal \( \lambda \) was chosen based on the lowest average
binomial deviance.

After selecting the optimal \( \lambda \), model performance was evaluated
using accuracy and AUC metrics. Additionally, a permutation test was conducted
100 times to calculate p-values for each covariate. Across all iterations, we
calculated the mean and standard deviation of the metrics, as well as the
percentage of significant p-values for each covariate.

\section*{Results}

In simulation 1, figure~\ref{fig:sim1_p_dist} shows the distribution of 
\( p \) for different values of \( \beta	\). \( \beta \) were evaluated with
value of 0.01, 0.05, 0.1, 0.2 and 1. We can see that when \( \beta = 0.1 \) does
it achieve an even spread of probabilities, thus the effect size of \( \beta \)
were set to 0.1.

\begin{figure}[H] 
	\centering
	\includegraphics[width=\textwidth]{../Figures/sim1_p_dist.png} 
	\caption{The distribution of \(p\) at different \(\beta\) values. \(\beta = 0.1\) was
chosen for model fitting as it gives the most evenly distributed values.}
	\label{fig:sim1_p_dist} 
\end{figure}

In simulation 2, figure~\ref{fig:sim2_p_dist} shows the distribution of \( p \)
for different values of \( b \). \( b \) were evaluated at 0.1, 0.2, 0.4, 0.6,
0.8 and 1. When \( b \) equals 0.4 did we achieve an even spread of
probabilites.

\begin{figure}[H] 
	\centering
	\includegraphics[width=\textwidth]{../Figures/sim2_p_dist.png} 
	\caption{The distribution of \(p\) at different \( b \) values. \( b = 0.4 \) was
chosen for model fitting as it gives the most evenly distributed values.}
	\label{fig:sim2_p_dist} 
\end{figure}





\end{document}
